{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff78c815-4448-48d2-8a72-a8a97c7d6f8f",
   "metadata": {},
   "source": [
    "# Realtime blockchain monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef93bd6c-2563-466e-9980-09a4229d0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from apache_beam.transforms.trigger import AfterProcessingTime, AccumulationMode\n",
    "import apache_beam as beam\n",
    "from apache_beam.runners.interactive import interactive_runner\n",
    "import apache_beam.runners.interactive.interactive_beam as ib\n",
    "from apache_beam.transforms import trigger\n",
    "from apache_beam.options import pipeline_options\n",
    "from apache_beam.options.pipeline_options import GoogleCloudOptions\n",
    "from apache_beam.io.gcp.bigtableio import WriteToBigTable\n",
    "from apache_beam.io.textio import WriteToText\n",
    "import google.auth\n",
    "import datetime\n",
    "\n",
    "project_id = \"forrest-test-project-333203\"\n",
    "instance_id = \"my-bigtable\"\n",
    "table_id = \"eth_address_meta\"\n",
    "dataflow_gcs_location = 'gs://forrest-bigdata-bucket/dataflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c5d8f8f-ab31-4234-bcd2-c2461d0e27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the Beam pipeline options.\n",
    "options = pipeline_options.PipelineOptions()\n",
    "\n",
    "# Sets the pipeline mode to streaming, so we can stream the data from PubSub.\n",
    "options.view_as(pipeline_options.StandardOptions).streaming = True\n",
    "\n",
    "# Sets the project to the default project in your current Google Cloud environment.\n",
    "# The project will be used for creating a subscription to the PubSub topic.\n",
    "_, options.view_as(GoogleCloudOptions).project = google.auth.default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152999d-e6d5-4550-9529-09f49bb296f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85abe72f-98fe-4b6e-963f-130eb9606348",
   "metadata": {},
   "source": [
    "## ETH address enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89177a97-424c-43b1-91d6-c695f73207a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnrichAddressMetaFn(beam.DoFn):\n",
    "    def __init__(self, project_id, instance_id, table_id):\n",
    "        self.project_id = project_id\n",
    "        self.instance_id = instance_id\n",
    "        self.table_id = table_id\n",
    "    \n",
    "    def start_bundle(self):\n",
    "        from google.cloud import bigtable\n",
    "        \n",
    "        client = bigtable.Client(project=self.project_id)\n",
    "        instance = client.instance(self.instance_id)\n",
    "        self.table = instance.table(self.table_id)\n",
    "    \n",
    "    def process(self, elem):\n",
    "        \n",
    "        from google.cloud.bigtable import row\n",
    "        import json\n",
    "\n",
    "        def add_prefix(data, prefix):\n",
    "            return {f\"{prefix}{k}\": v for k, v in data.items()}\n",
    "        \n",
    "        column_family_id = \"cf1\"\n",
    "        column_id = \"meta\".encode()\n",
    "        row_key_from = elem.get(\"from_address\", None)\n",
    "        row_key_to = elem.get(\"to_address\", None)\n",
    "        row_from = self.table.read_row(row_key_from.encode()) if row_key_from else None \n",
    "        row_to = self.table.read_row(row_key_to.encode()) if row_key_to else None\n",
    "        \n",
    "        default_json = {\n",
    "            \"name\": None,\n",
    "            \"account_type\": None,\n",
    "            \"contract_type\": None,\n",
    "            \"entity\": None,\n",
    "            \"label\": None,\n",
    "            \"tags\": [],\n",
    "            \"created_at\": None\n",
    "        }\n",
    "        value_from = json.loads(row_from.cells[column_family_id][column_id][0].value.decode('utf-8')) if row_from else default_json\n",
    "        value_to = json.loads(row_to.cells[column_family_id][column_id][0].value.decode('utf-8')) if row_to else default_json\n",
    "\n",
    "        elem[\"amount\"] = elem[\"value\"]\n",
    "        elem.pop(\"nonce\")\n",
    "        elem.pop(\"input\")\n",
    "        elem.pop(\"value\")\n",
    "        \n",
    "        elem = {**elem, \"from_address_meta\": value_from, \"to_address_meta\": value_to}\n",
    "\n",
    "        yield json.dumps(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fd1648b-ac3f-4cb2-a21a-682cdab33f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following code for interactive beam\n",
    "# p = beam.Pipeline(interactive_runner.InteractiveRunner(), options=options)\n",
    "# subscription = \"projects/forrest-test-project-333203/subscriptions/ethTransactionTest\"\n",
    "\n",
    "# uncomment the following code for dataflow runner\n",
    "p = beam.Pipeline(options=options)\n",
    "subscription = \"projects/forrest-test-project-333203/subscriptions/ethTransactionParser\"\n",
    "\n",
    "output_topic = \"projects/forrest-test-project-333203/topics/blockchain.eth.transactions_enriched\"\n",
    "\n",
    "enrich_pipeline = (\n",
    "    p\n",
    "    | \"read from pubsub\" >> beam.io.ReadFromPubSub(subscription=subscription)\n",
    "    | 'transform to json' >> beam.Map(json.loads)\n",
    "    | 'enrich with address meta' >> beam.ParDo(EnrichAddressMetaFn(project_id, instance_id, table_id))\n",
    "    | 'UTF-8 encode' >> beam.Map(lambda s: s.encode(\"utf-8\"))\n",
    "    | 'write to pubsub' >> beam.io.WriteToPubSub(topic=output_topic)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f77e3a-1398-4980-85d6-188dbb269845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive runner\n",
    "ib.options.recording_duration = '2m'\n",
    "ib.show(enrich_pipeline, include_window_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f91ad-93e5-423b-95ee-7603d568930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataflow runner\n",
    "from apache_beam.runners import DataflowRunner\n",
    "\n",
    "options.view_as(GoogleCloudOptions).region = 'us-central1'\n",
    "options.view_as(GoogleCloudOptions).staging_location = '%s/staging' % dataflow_gcs_location\n",
    "options.view_as(GoogleCloudOptions).temp_location = '%s/temp' % dataflow_gcs_location\n",
    "options.view_as(GoogleCloudOptions).job_name = f\"eth-transaction-enrich-job-{int(datetime.datetime.utcnow().timestamp())}\"\n",
    "options.view_as(GoogleCloudOptions).service_account_email = \"notebook@forrest-test-project-333203.iam.gserviceaccount.com\"\n",
    "options.view_as(GoogleCloudOptions).update = False\n",
    "options.view_as(pipeline_options.WorkerOptions).network = \"bigdata-network\"\n",
    "options.view_as(pipeline_options.WorkerOptions).subnetwork = \"regions/us-central1/subnetworks/dataflow-network\"\n",
    "options.view_as(pipeline_options.WorkerOptions).use_public_ips = False\n",
    "options.view_as(pipeline_options.SetupOptions).save_main_session = False\n",
    "\n",
    "runner = DataflowRunner()\n",
    "runner.run_pipeline(p, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cd342c-fa22-443a-82fb-2054f6d5da58",
   "metadata": {},
   "source": [
    "# Export from big query to bigtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8dab31-a4ea-4194-ba02-3d7dda904a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for buiding bigtable row\n",
    "class CreateRowFn(beam.DoFn):\n",
    "    def process(self, elem):\n",
    "        \n",
    "        from google.cloud.bigtable import row\n",
    "        import datetime\n",
    "        import json\n",
    "\n",
    "        row_key = elem.pop(\"address\")\n",
    "        elem[\"created_at\"] = int(datetime.datetime.timestamp(elem[\"created_at\"]))\n",
    "        \n",
    "        direct_row = row.DirectRow(row_key=row_key)\n",
    "        direct_row.set_cell(\n",
    "            'cf1',\n",
    "            'meta',\n",
    "            json.dumps(elem).encode())\n",
    "        \n",
    "        yield direct_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bbe84-e45b-45d5-a1c3-513d3adb8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for print row\n",
    "class JsonToStringFn(beam.DoFn):\n",
    "    def process(self, elem):\n",
    "        import datetime\n",
    "        import json\n",
    "\n",
    "        row_key = elem.pop(\"address\")\n",
    "        elem[\"created_at\"] = int(datetime.datetime.timestamp(elem[\"created_at\"]))\n",
    "        \n",
    "        yield json.dumps(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637679b-db1a-4b4c-bca9-9b0d7130023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = pipeline_options.PipelineOptions()\n",
    "_, options.view_as(GoogleCloudOptions).project = google.auth.default()\n",
    "options.view_as(GoogleCloudOptions).temp_location = '%s/temp' % dataflow_gcs_location\n",
    "\n",
    "p = beam.Pipeline(options=options)\n",
    "\n",
    "export_pipeline = (\n",
    "    p\n",
    "    | \"read from bigquery\" >> beam.io.ReadFromBigQuery(\n",
    "        query='select * from forrest-test-project-333203.crypto.eth_address_tag', \n",
    "        use_standard_sql=True)\n",
    "    # | \"json to string\" >> beam.ParDo(JsonToStringFn())\n",
    "    # | \"print\" >> beam.Map(print)\n",
    "    | \"create bigtable row\" >> beam.ParDo(CreateRowFn())\n",
    "    | 'Write to bigtable' >> WriteToBigTable(\n",
    "        project_id=project_id,\n",
    "        instance_id=instance_id,\n",
    "        table_id=table_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceffe523-d369-4c62-a5a7-c0386ecf0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a1f170-26f5-4858-8660-ecf4687f3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from apache_beam.runners import DataflowRunner\n",
    "\n",
    "options.view_as(GoogleCloudOptions).region = 'us-central1'\n",
    "options.view_as(GoogleCloudOptions).staging_location = '%s/staging' % dataflow_gcs_location\n",
    "options.view_as(GoogleCloudOptions).temp_location = '%s/temp' % dataflow_gcs_location\n",
    "options.view_as(GoogleCloudOptions).job_name = f\"export-to-bigquery-job-{int(datetime.datetime.utcnow().timestamp())}\"\n",
    "options.view_as(GoogleCloudOptions).service_account_email = \"notebook@forrest-test-project-333203.iam.gserviceaccount.com\"\n",
    "options.view_as(GoogleCloudOptions).update = False\n",
    "options.view_as(pipeline_options.WorkerOptions).network = \"bigdata-network\"\n",
    "options.view_as(pipeline_options.WorkerOptions).subnetwork = \"regions/us-central1/subnetworks/dataflow-network\"\n",
    "options.view_as(pipeline_options.WorkerOptions).use_public_ips = False\n",
    "options.view_as(pipeline_options.SetupOptions).save_main_session = False\n",
    "\n",
    "runner = DataflowRunner()\n",
    "runner.run_pipeline(p, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bb5ad1-40b7-4bca-ba16-0378ad04dec1",
   "metadata": {},
   "source": [
    "# Run a filter pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f1e772-f98b-481d-ac4b-59e802f90336",
   "metadata": {},
   "source": [
    "This an example of submitting a dataflow job to filter transaction. In this example we filter transactions based on the following criteria:\n",
    "- The transaction is successful (receipt_status = 1)\n",
    "- The amount is greter than 100\n",
    "- Or the from or to address is owned by exchange and amount is greater than 10\n",
    "\n",
    "The dataflow job will output the results to a pubsub topic specified in the --output_topic parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ccecf-e31d-4cdc-830d-df7d01e53258",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /home/jupyter/realtime-eth-monitoring/eth_monitoring.py \\\n",
    "    --subscription projects/forrest-test-project-333203/subscriptions/ethTransactionEnriched \\\n",
    "    --output_topic projects/forrest-test-project-333203/topics/blockchain.eth.whale_alert \\\n",
    "    --sql \"SELECT cast(cast(block_timestamp * 1000 as timestamp) as varchar) ts, hash, amount, gas * gas_price as gas_fee, \\\n",
    "               from_address, \\\n",
    "               from_address_name, \\\n",
    "               from_address_account_type, \\\n",
    "               from_address_contract_type, \\\n",
    "               from_address_entity, \\\n",
    "               from_address_label, \\\n",
    "               from_address_tags, \\\n",
    "               (CASE \\\n",
    "                   WHEN from_address_created_at is NOT NULL THEN cast(cast(from_address_created_at * 1000 as timestamp) as varchar) \\\n",
    "                   ELSE NULL \\\n",
    "               END) from_address_created_at, \\\n",
    "               to_address, \\\n",
    "               to_address_name, \\\n",
    "               to_address_account_type, \\\n",
    "               to_address_contract_type, \\\n",
    "               to_address_entity, \\\n",
    "               to_address_label, \\\n",
    "               to_address_tags, \\\n",
    "               (CASE \\\n",
    "                   WHEN to_address_created_at is NOT NULL THEN cast(cast(to_address_created_at * 1000 as timestamp) as varchar) \\\n",
    "                   ELSE NULL \\\n",
    "               END) to_address_created_at \\\n",
    "           FROM PCOLLECTION \\\n",
    "           WHERE receipt_status = 1 \\\n",
    "           AND (amount >= 100 \\\n",
    "               OR (LOWER(from_address_entity) = 'exchange' and amount >= 10) \\\n",
    "               OR (LOWER(to_address_entity) = 'exchange' and amount >= 10))\" \\\n",
    "    --decimal 1000000000000000000 \\\n",
    "    --region us-central1 \\\n",
    "    --project forrest-test-project-333203 \\\n",
    "    --temp_location gs://forrest-bigdata-bucket/dataflow/temp \\\n",
    "    --staging_location gs://forrest-bigdata-bucket/dataflow/staging \\\n",
    "    --job_name eth-whale-alert-$(date +%s) \\\n",
    "    --service_account_email \"notebook@forrest-test-project-333203.iam.gserviceaccount.com\" \\\n",
    "    --enable_streaming_engine \\\n",
    "    --network bigdata-network \\\n",
    "    --subnetwork regions/us-central1/subnetworks/dataflow-network \\\n",
    "    --no_use_public_ips \\\n",
    "    --runner DataflowRunner \\\n",
    "    --machine_type n1-standard-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc2cf1e7-efa4-4dab-a098-29acc82f8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "class Data(NamedTuple):\n",
    "    name: str\n",
    "    age: int\n",
    "    \n",
    "a=Data(\"test\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac71d75-f94a-4568-9876-807af1f74e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(name='test', age=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8203902-4117-4c1a-a055-f143ea99dd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Data"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42199ca9-418b-41a6-8509-85dc1858fd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('name', 'test'), ('age', 1)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a._asdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78918da0-e876-4e85-b6d8-510a5a889d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"test\", \"age\": 1}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(a._asdict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe5038-2d94-433a-b868-cf0cdfaeef04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "01. Apache Beam 2.34.0 for Python 3",
   "language": "python",
   "name": "01-apache-beam-2.34.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
